<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head>
	<meta name="generator" content="Hugo 0.152.2"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>My work notes</title>

<meta name="description" content="è®°å½•è®ºæ–‡é˜…è¯»ä¸ä»£ç å®è·µ">
<meta name="author" content="fandengdong">
<link rel="canonical" href="http://localhost:1313/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css" integrity="sha256-NDzEgLn/yPBMy&#43;XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/index.xml" title="rss">
<link rel="alternate" hreflang="en" href="http://localhost:1313/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="http://localhost:1313/">
  <meta property="og:site_name" content="My work notes">
  <meta property="og:title" content="æ¬¢è¿æ¥åˆ°æˆ‘çš„å·¥ä½œç©ºé—´">
  <meta property="og:description" content=" ğŸ“š æˆ‘çš„å·¥ä½œç¬”è®° è¿™é‡Œè®°å½•æˆ‘åœ¨äººå·¥æ™ºèƒ½ã€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¼€å‘å·¥å…·æ–¹é¢çš„å­¦ä¹ ä¸å®è·µã€‚ æ¬¢è¿ä¸€èµ·æ¢ç´¢æŠ€æœ¯çš„è¾¹ç•Œï¼ ğŸ§  RL ğŸ’¬ LLM ğŸ§° å·¥å…·ç®± ">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="æ¬¢è¿æ¥åˆ°æˆ‘çš„å·¥ä½œç©ºé—´">
<meta name="twitter:description" content="è®°å½•è®ºæ–‡é˜…è¯»ä¸ä»£ç å®è·µ">

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "My work notes",
  "url": "http://localhost:1313/",
  "description": "è®°å½•è®ºæ–‡é˜…è¯»ä¸ä»£ç å®è·µ",
  "logo": "http://localhost:1313/favicon.ico",
  "sameAs": [
      
  ]
}
</script>
</head>
<body class="list" id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="My work notes (Alt + H)">My work notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/llm/" title="å¤§è¯­è¨€æ¨¡å‹ (LLM)">
                    <span>å¤§è¯­è¨€æ¨¡å‹ (LLM)</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/toolbox/" title="å·¥å…·ç®± (toolbox)">
                    <span>å·¥å…·ç®± (toolbox)</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/rl/" title="å¼ºåŒ–å­¦ä¹  (RL)">
                    <span>å¼ºåŒ–å­¦ä¹  (RL)</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/" title="æ¬¢è¿æ¥åˆ°æˆ‘çš„å·¥ä½œç©ºé—´">
                    <span class="active">æ¬¢è¿æ¥åˆ°æˆ‘çš„å·¥ä½œç©ºé—´</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<div class="post-content"><div style="text-align: center; max-width: 700px; margin: 2rem auto; padding: 0 1rem;">
  <h2>ğŸ“š æˆ‘çš„å·¥ä½œç¬”è®°</h2>
  <p style="font-size: 1.1em; color: #555; line-height: 1.6;">
    è¿™é‡Œè®°å½•æˆ‘åœ¨äººå·¥æ™ºèƒ½ã€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¼€å‘å·¥å…·æ–¹é¢çš„å­¦ä¹ ä¸å®è·µã€‚
    æ¬¢è¿ä¸€èµ·æ¢ç´¢æŠ€æœ¯çš„è¾¹ç•Œï¼
  </p>
<div style="display: flex; justify-content: center; gap: 2rem; margin-top: 2rem; flex-wrap: wrap;">
  <a href="/rl/" class="btn btn-primary" style="display: inline-block; padding: 0.8rem 1.5rem; background: #f0f8ff; border-radius: 12px; text-decoration: none; color: #2c3e50; font-weight: bold; box-shadow: 0 2px 6px rgba(0,0,0,0.1); transition: transform 0.2s, box-shadow 0.2s;">
    ğŸ§  RL
  </a>

  <a href="/llm/" class="btn btn-primary" style="display: inline-block; padding: 0.8rem 1.5rem; background: #f0f8ff; border-radius: 12px; text-decoration: none; color: #2c3e50; font-weight: bold; box-shadow: 0 2px 6px rgba(0,0,0,0.1); transition: transform 0.2s, box-shadow 0.2s;">
    ğŸ’¬ LLM
  </a>

  <a href="/toolbox/" class="btn btn-primary" style="display: inline-block; padding: 0.8rem 1.5rem; background: #f0f8ff; border-radius: 12px; text-decoration: none; color: #2c3e50; font-weight: bold; box-shadow: 0 2px 6px rgba(0,0,0,0.1); transition: transform 0.2s, box-shadow 0.2s;">
    ğŸ§° å·¥å…·ç®±
  </a>

</div>
  </div>
</div>


</div>

<article class="first-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">ä½¿ç”¨ Mindspeed-LLMè¿›è¡Œæ¨ç†
    </h2>
  </header>
  <div class="entry-content">
    <p>è®°å½•mindspeed-llmæ¡†æ¶æä¾›çš„æ¨ç†æ–¹æ³•ï¼Œè¿™é‡Œè®°å½•ç”¨Qwen2.5-7Bæ¨¡å‹æ¨ç†è¿‡ç¨‹ã€‚
å‡†å¤‡å·¥ä½œ æ¨ç†æ¨¡å‹çš„æƒé‡ï¼ŒåŒæ ·éœ€è¦è½¬æ¢ä¸ºmcoreæ ¼å¼ï¼Œæ–¹æ³•åŒå¾®è°ƒä¸€æ ·ï¼Œå‚è€ƒè¿™é‡Œ
å¼€å¯æ¨ç†æµ‹è¯• å‡†å¤‡å¥½æ¨¡å‹æƒé‡åï¼Œå¯ä»¥ç›´æ¥åˆ©ç”¨mindspeed-llmæä¾›çš„æ¨ç†è„šæœ¬è¿›è¡Œæ¨ç†æµ‹è¯•ï¼Œè„šæœ¬ä½äºexamples/mcore/qwen25/generate_qwen25_7b_ptd.sh
#!/bin/bash export CUDA_DEVICE_MAX_CONNECTIONS=1 # please fill these path configurations CHECKPOINT=&#34;/home/fdd/workspace/models/Qwen/Qwen2.5-7B/mcore_tp1_pp1/&#34; TOKENIZER_PATH=&#34;/home/fdd/workspace/models/Qwen/Qwen2.5-7B-Instruct/&#34; # Change for multinode config MASTER_ADDR=localhost MASTER_PORT=6000 NNODES=1 NODE_RANK=0 NPUS_PER_NODE=1 WORLD_SIZE=$(($NPUS_PER_NODE*$NNODES)) TP=1 PP=1 SEQ_LENGTH=32768 ... torchrun $DISTRIBUTED_ARGS inference.py \ --use-mcore-models \ ... å¯ä»¥çœ‹åˆ°å¯¹äº7Bæ¨¡å‹ï¼Œé‡‡ç”¨å•å¡å°±å¯ä»¥è¿›è¡Œæ¨ç†äº†ã€‚å¦å¤–ï¼Œå¯åŠ¨æ–¹å¼ä¾ç„¶ä¸ºtorchrunï¼Œå¯åŠ¨è„šæœ¬ä¸ºinference.pyã€‚
æ¨ç†æµç¨‹ æŸ¥çœ‹inference.pyæ–‡ä»¶ï¼š
from megatron.training.initialize import initialize_megatron from mindspeed_llm.tasks.inference.module import GPTModelInfer, MegatronModuleForCausalLM def main(): initialize_megatron(args_defaults={&#39;no_load_rng&#39;: True, &#39;no_load_optim&#39;: True}) args = get_args() model = MegatronModuleForCausalLM.from_pretrained( model_provider=model_provider, pretrained_model_name_or_path=args.load ) task_factory(args, model) if __name__ == &#34;__main__&#34;: main() å¯ä»¥çœ‹åˆ°åˆå§‹åŒ–megatronç¯å¢ƒçš„æ—¶å€™ï¼Œè°ƒç”¨äº†initialize_megatronæ–¹æ³•ï¼ˆè®­ç»ƒä¹Ÿæ˜¯è°ƒç”¨è¿™ä¸ªæ¥å£æ¥åˆå§‹åŒ–ï¼‰ï¼Œå¹¶ä¸”ç¦ç”¨äº†éšæœºæ•°åŠ è½½å’Œä¼˜åŒ–å™¨åŠ è½½åŠŸèƒ½ï¼Œå› ä¸ºæ¨ç†ä¸éœ€è¦ã€‚å¦å¤–ï¼Œè°ƒç”¨äº†MegatronModuleForCausalLMçš„ç±»æ–¹æ³•from_pretrainedæ¥åˆå§‹åŒ–æ¨¡å‹ï¼Œå…¶ä¸­MegatronModuleForCausalLMæ˜¯ä¸€ä¸ªç”¨äºæ¨ç†çš„ä¸“æœ‰classã€‚æœ€åæ ¹æ®args.taskå‚æ•°ï¼Œè°ƒç”¨task_factoryæ–¹æ³•æ¥æ‰§è¡Œä»»åŠ¡ã€‚
æˆ‘ä»¬è¿›ä¸€æ­¥çœ‹ä¸‹æ¨ç†æ¨¡å‹çš„ç»“æ„ï¼Œå³model_providerå†…å®¹ï¼š
def model_provider(pre_process=True, post_process=True): ... if args.spec is not None: transformer_layer_spec = import_module(args.spec) else: if use_te: transformer_layer_spec = get_gpt_layer_with_transformer_engine_spec(args.num_experts, args.moe_grouped_gemm) else: transformer_layer_spec = get_gpt_layer_local_spec(args.num_experts, args.moe_grouped_gemm) model = GPTModelInfer( config=config, transformer_layer_spec=transformer_layer_spec, vocab_size=args.padded_vocab_size, max_sequence_length=args.max_position_embeddings, pre_process=pre_process, post_process=post_process, fp16_lm_cross_entropy=args.fp16_lm_cross_entropy, parallel_output=True if args.sequence_parallel else False, share_embeddings_and_output_weights=not args.untie_embeddings_and_output_weights, position_embedding_type=args.position_embedding_type, rotary_percent=args.rotary_percent, seq_len_interpolation_factor=args.rotary_seq_len_interpolation_factor ) ... return model è¿™é‡Œå…³é”®çœ‹GPTModelInferçš„å®šä¹‰ï¼š
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-14 00:00:00 +0000 UTC'>November 14, 2025</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to ä½¿ç”¨ Mindspeed-LLMè¿›è¡Œæ¨ç†" href="http://localhost:1313/llm/mindspeed_llm/mindspeed_llm_inference/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">ä½¿ç”¨ Mindspeed-LLMè¿›è¡Œé¢„è®­ç»ƒ
    </h2>
  </header>
  <div class="entry-content">
    <p>æœ¬æŒ‡å—è®°å½•é‡‡ç”¨mindspeed-llmè¿›è¡Œè®­ç»ƒçš„æ­¥éª¤ï¼Œä»¥å¾®è°ƒä¸ºä¾‹ã€‚
å‡†å¤‡æ•°æ® å‡†å¤‡æ•°æ®é›†çš„jsonlæ–‡ä»¶ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè‡³å°‘è¦åŒ…å«å…³é”®å­—promptå’Œresponseï¼Œå…¶ä¸­promptä¸ºè¾“å…¥ï¼Œresponseä¸ºè¾“å‡ºã€‚
æ³¨æ„ï¼šå¦‚æœæä¾›çš„jsonlæ–‡ä»¶é‡Œé¢æ²¡æœ‰åŒ…å«chat templateï¼Œé‚£ä¹ˆåœ¨è½¬æ¢æ•°æ®çš„æ—¶å€™è¦æ·»åŠ prompt-typeå‚æ•°æ¥æä¾›æ¨¡æ¿ã€‚ä¸‹é¢æä¾›ä¸€ä¸ªå¸¦äº†chat templatedçš„jsonlæ–‡ä»¶æ ·ä¾‹ï¼š
{&#34;prompt&#34;:&#34;&lt;|im_start|&gt;system\nYou are a helpful assistant. To answer the user\&#39;s question, you first think about the reasoning process and then provide the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;\/think&gt; and &lt;answer&gt; &lt;\/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;\/think&gt; &lt;answer&gt; answer here &lt;\/answer&gt;.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nLet $\\triangle ABC$ have circumcenter $O$ and incenter $I$ with $\\overline{IA}\\perp\\overline{OI}$, circumradius $13$, and inradius $6$. Find $AB\\cdot AC$.\nPlease reason step by step, and put your final answer within \\boxed{}.\nPlease reason step by step, and put your final answer within \\boxed{}.&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&#34;,&#34;response&#34;:&#34;&lt;think&gt;\nI have a geometry problem. We have a triangle ABC with circumcenter O and incenter I....&#34;} {&#34;prompt&#34;:&#34;&lt;|im_start|&gt;system\nYou are a helpful assistant. To answer the user\&#39;s question, you first think about the reasoning process and then provide the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;\/think&gt; and &lt;answer&gt; &lt;\/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;\/think&gt; &lt;answer&gt; answer here &lt;\/answer&gt;.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nLet \\(b\\ge 2\\) be an integer. Call a positive integer \\(n\\) \\(b\\text-\\textit{eautiful}\\) if it has exactly two digits when expressed in base \\(b\\) and these two digits sum to \\(\\sqrt n\\). For example, \\(81\\) is \\(13\\text-\\textit{eautiful}\\) because \\(81 = \\underline{6} \\ \\underline{3}_{13} \\) and \\(6 &#43; 3 = \\sqrt{81}\\). Find the least integer \\(b\\ge 2\\) for which there are more than ten \\(b\\text-\\textit{eautiful}\\) integers.\nPlease reason step by step, and put your final answer within \\boxed{}.\nPlease reason step by step, and put your final answer within \\boxed{}.&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&#34;,&#34;response&#34;:&#34;&lt;think&gt;\nThe problem defines a \&#34;b-beautiful\&#34; number as a positive integer...&#34;} å‡†å¤‡å¥½jsonlæ–‡ä»¶åï¼Œåˆ©ç”¨mindspeed-llmè‡ªå¸¦çš„è„šæœ¬preprocess_data.pyæ¥é¢„å¤„ç†æ•°æ®ï¼š
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-14 00:00:00 +0000 UTC'>November 14, 2025</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to ä½¿ç”¨ Mindspeed-LLMè¿›è¡Œé¢„è®­ç»ƒ" href="http://localhost:1313/llm/mindspeed_llm/mindspeed_llm_finetune/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">å¼€å§‹ä½¿ç”¨ Mindspeed è¿›è¡Œå¤§æ¨¡å‹è®­ç»ƒ
    </h2>
  </header>
  <div class="entry-content">
    <p>æœ¬æ–‡é€šè¿‡ä¸€ä¸ªå®Œæ•´ç¤ºä¾‹ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Mindspeed æ¡†æ¶è¿›è¡Œåˆ†å¸ƒå¼å¤§æ¨¡å‹è®­ç»ƒã€‚
ç¯å¢ƒç‰ˆæœ¬ä¿¡æ¯
Mindspeed commit ID: 89f4632d Megatron åˆ†æ”¯: core_v0.12.1 CANN: 8.2.RC1 PyTorch: 2.5.1 1. åˆå§‹åŒ–åˆ†å¸ƒå¼å¹¶è¡Œç¯å¢ƒ Mindspeed åŸºäº Megatron æ„å»ºï¼Œæ”¯æŒå¼ é‡å¹¶è¡Œï¼ˆTPï¼‰å’Œæµæ°´çº¿å¹¶è¡Œï¼ˆPPï¼‰ã€‚åœ¨è®­ç»ƒå‰ï¼Œå¿…é¡»æ­£ç¡®åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒï¼š
import os import torch import mindspeed.megatron_adaptor # å…³é”®ï¼šç¡®ä¿ Mindspeed ä¸ Megatron API å…¼å®¹ from megatron.core import parallel_state def initialize_distributed(tensor_model_parallel_size=1, pipeline_model_parallel_size=1): # æ¸…ç†å·²æœ‰çŠ¶æ€ï¼ˆé˜²æ­¢é‡å¤åˆå§‹åŒ–ï¼‰ parallel_state.destroy_model_parallel() # æ ‡å‡† PyTorch åˆ†å¸ƒå¼è®¾ç½® rank = int(os.environ.get(&#39;LOCAL_RANK&#39;, 0)) world_size = int(os.environ.get(&#34;WORLD_SIZE&#34;, 1)) torch.cuda.set_device(rank) torch.distributed.init_process_group(world_size=world_size, rank=rank) # åˆå§‹åŒ– Megatron å¹¶è¡ŒçŠ¶æ€ parallel_state.initialize_model_parallel( tensor_model_parallel_size=tensor_model_parallel_size, pipeline_model_parallel_size=pipeline_model_parallel_size ) å…³é”®ç‚¹è¯´æ˜ï¼š å¿…é¡»æ˜¾å¼å¯¼å…¥ mindspeed.megatron_adaptorï¼Œä»¥å¯ç”¨å…¼å®¹å±‚ã€‚ é™¤äº†æ ‡å‡†çš„ torch.distributed.init_process_groupï¼Œè¿˜éœ€è°ƒç”¨ parallel_state.initialize_model_parallel æ¥æ¿€æ´» TP/PP æ”¯æŒã€‚ éœ€æ ¹æ®å®é™…è®­ç»ƒé…ç½®ä¼ å…¥ tensor_model_parallel_size å’Œ pipeline_model_parallel_sizeã€‚
Mindspeed æ¨¡å‹åˆå§‹åŒ– Mindspeed ä½¿ç”¨ Megatron Core çš„æ¨¡å—åŒ–è®¾è®¡æ„å»ºæ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªæœ€å° GPT æ¨¡å‹çš„æ„å»ºç¤ºä¾‹ï¼š
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-11 00:00:00 +0000 UTC'>November 11, 2025</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to å¼€å§‹ä½¿ç”¨ Mindspeed è¿›è¡Œå¤§æ¨¡å‹è®­ç»ƒ" href="http://localhost:1313/llm/mindspeed/get_started_with_mindspeed/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">MindspeedåŸºæœ¬ä»‹ç»
    </h2>
  </header>
  <div class="entry-content">
    <p>MindSpeedçš„æ ¸å¿ƒç›®çš„æ˜¯é«˜æ•ˆåœ°é€‚é…å’ŒåŠ é€ŸåŸºäºMegatron-LMçš„å¤§æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨åä¸ºæ˜‡è…¾AIç¡¬ä»¶ä¸Šè¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚å…¶ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
æ¡†æ¶å…¼å®¹æ€§ï¼šå°†åŸç”ŸMegatron-LMä»£ç é€‚é…åˆ°æ˜‡è…¾NPUæ¶æ„ï¼Œç¡®ä¿åŠŸèƒ½æ­£ç¡®æ€§ã€‚ æ€§èƒ½ä¼˜åŒ–ï¼šé€šè¿‡ç®—å­èåˆã€å†…å­˜ä¼˜åŒ–å’Œé€šä¿¡åŠ é€Ÿç­‰æŠ€æœ¯æå‡è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚ å¤šçº§åŠ é€Ÿï¼šæä¾›å¯é…ç½®çš„ä¼˜åŒ–å±‚çº§ï¼ˆå¦‚åŸºç¡€å…¼å®¹æ€§ã€äº²å’Œæ€§å¢å¼ºã€å…¨é¢åŠ é€Ÿï¼‰ï¼Œç”¨æˆ·å¯æ ¹æ®éœ€æ±‚å¯ç”¨ã€‚ ç”Ÿæ€é›†æˆï¼šä¸CANNå’ŒMindSporeç­‰æ˜‡è…¾è½¯ä»¶æ ˆæ·±åº¦é›†æˆï¼Œå®ç°æ— ç¼çš„è½¯ç¡¬ä»¶ååŒä¼˜åŒ–ã€‚ ç®€è€Œè¨€ä¹‹ï¼ŒMindSpeedä½¿åŸºäºMegatronçš„å¤§æ¨¡å‹èƒ½å¤Ÿåœ¨æ˜‡è…¾è®¾å¤‡ä¸Šæ­£ç¡®è¿è¡Œã€å¿«é€Ÿè¿è¡Œå’Œå¯é è¿è¡Œã€‚
ä¸€è¡Œä»£ç é€‚é…Megatronä»£ç  import torch import mindspeed.megatron_adaptor # æ–°å¢ä»£ç è¡Œ åŠ é€Ÿç‰¹æ€§å±‚çº§è¯´æ˜ MindSpeed CoreåŠ é€Ÿç‰¹æ€§åˆ†ä¸ºä¸‰ä¸ªå±‚çº§ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡åœ¨å¯åŠ¨è„šæœ¬ä¸­è®¾ç½®--optimization-level {level}å‚æ•°æ¥æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©è¦å¯ç”¨çš„ä¼˜åŒ–çº§åˆ«ã€‚è¯¥å‚æ•°æ”¯æŒä»¥ä¸‹é…ç½®ï¼š
ç­‰çº§ ç­‰çº§åç§° æè¿° 0 åŸºç¡€åŠŸèƒ½å…¼å®¹æ€§ æä¾›Megatron-LMæ¡†æ¶ä¸NPUçš„åŸºç¡€åŠŸèƒ½å…¼å®¹æ€§ã€‚ 1 äº²å’Œæ€§å¢å¼º ğŸ”¥ åœ¨L0åŸºç¡€ä¸Šï¼Œå¯ç”¨éƒ¨åˆ†èåˆç®—å­å’Œæ˜‡è…¾å‹å¥½çš„è®¡ç®—é‡å†™ã€‚ 2 åŠ é€Ÿç‰¹æ€§å¢å¼º ğŸ”¥ğŸ”¥ é»˜è®¤å€¼ã€‚åœ¨L0å’ŒL1åŸºç¡€ä¸Šå¯ç”¨æ›´ä¸°å¯Œçš„åŠ é€Ÿç‰¹æ€§ï¼ŒåŠ é€Ÿç‰¹æ€§é€šå¸¸é€šè¿‡ç‰¹å®šå‚æ•°å¯ç”¨ã€‚è¯¦æƒ…è¯·å‚é˜…&#34;ç‰¹æ€§ä»‹ç»&#34;éƒ¨åˆ†ã€‚ MindSpeed Coreç”Ÿæ€ç³»ç»Ÿ åœ¨MindSpeed CoreåŠ é€Ÿåº“çš„åŸºç¡€ä¸Šï¼Œè¿˜æä¾›äº†ä»¥ä¸‹ä¸“ä¸šåº“ï¼š
å¤§è¯­è¨€æ¨¡å‹åº“: MindSpeed LLM å¤šæ¨¡æ€æ¨¡å‹åº“: MindSpeed MM å¼ºåŒ–å­¦ä¹ åŠ é€Ÿåº“: MindSpeed RL </p>
  </div>
  <footer class="entry-footer"><span title='2025-11-10 00:00:00 +0000 UTC'>November 10, 2025</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to MindspeedåŸºæœ¬ä»‹ç»" href="http://localhost:1313/llm/mindspeed/introduction_with_mindspeed/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Deploying vLLM in Production
    </h2>
  </header>
  <div class="entry-content">
    <p>Getting Started with vLLM Deployment Deploying large language models efficiently requires careful consideration of hardware resources and configuration parameters.
Installation Installing vLLM is straightforward using pip:
pip install vllm </p>
  </div>
  <footer class="entry-footer"><span title='2024-01-20 00:00:00 +0000 UTC'>January 20, 2024</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to Deploying vLLM in Production" href="http://localhost:1313/llm/vllm/deployment/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">vLLM Optimization Techniques
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduction In this post, weâ€™ll explore the key optimization techniques that make vLLM one of the most efficient inference engines for large language models.
Key Optimizations PagedAttention PagedAttention is vLLMâ€™s core innovation that efficiently manages the GPU memory for attention keys and values. This technique significantly reduces memory fragmentation and allows for serving more requests simultaneously.
Continuous Batching Unlike traditional static batching, vLLM employs continuous batching which dynamically adds new requests to the batch as they arrive, improving throughput without increasing latency.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-15 00:00:00 +0000 UTC'>January 15, 2024</span>&nbsp;Â·&nbsp;<span>fandengdong</span></footer>
  <a class="entry-link" aria-label="post link to vLLM Optimization Techniques" href="http://localhost:1313/llm/vllm/optimization/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">My work notes</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
